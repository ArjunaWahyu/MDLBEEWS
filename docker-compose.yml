version: '3.8'

services:
  # data_consumer:
  #   build:
  #     context: ./data_consumer
  #   deploy:
  #     replicas: 1
  #   networks:
  #     - kafka_network
  #   tty: true
  #   depends_on:
  #     - kafka
  #   restart: always

  # rabbitmq:
  #   image: rabbitmq:3-management
  #   container_name: rabbitmq
  #   ports:
  #     - "5672:5672"
  #     - "15672:15672"
  #   environment:
  #     RABBITMQ_DEFAULT_USER: admin
  #     RABBITMQ_DEFAULT_PASS: password
  #   volumes:
  #     - ./rabbitmq/data:/var/lib/rabbitmq
  #   restart: always

  # rabbitmq:
  #   image: rabbitmq:3.13
  #   container_name: rabbitmq
  #   ports:
  #     - "5552:5552"
  #     - "15672:15672"
  #     - "5672:5672"
  #   environment:
  #     RABBITMQ_DEFAULT_USER: admin
  #     RABBITMQ_DEFAULT_PASS: password
  #     RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbitmq_stream advertised_host localhost
  #   command: >
  #     sh -c "
  #       rabbitmq-plugins enable rabbitmq_stream rabbitmq_stream_management &&
  #       rabbitmq-server
  #     "
  #   restart: unless-stopped

  zookeeper:
    image: wurstmeister/zookeeper
    restart: always
    container_name: zookeeper
    ports:
      - "2182:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    # networks:
    #   - kafka_network

  kafka1:
    image: wurstmeister/kafka
    tty: true
    restart: always
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      # broker id
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_HOST_NAME: kafka1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_LOG_RETENTION_MS: 600000  # 10 menit
      # KAFKA_LOG_SEGMENT_BYTES: 1048576  # 1 MB
      # KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1 GB
      # KAFKA_HEAP_OPTS: "-Xmx256m -Xms256m -XX:+UseG1GC"  # Set JVM heap size to 256MB
      KAFKA_NUM_PARTITIONS: 3
    # deploy:
    #   resources:
    #     limits:
    #       memory: 5G
    # networks:
    #   - kafka_network
    depends_on:
      - zookeeper

  kafka2:
    image: wurstmeister/kafka
    tty: true
    restart: always
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      # broker id
      KAFKA_BROKER_ID: 2
      KAFKA_ADVERTISED_HOST_NAME: kafka2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      KAFKA_LOG_RETENTION_MS: 600000  # 10 menit
      # KAFKA_LOG_SEGMENT_BYTES: 1048576  # 1 MB
      # KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1 GB
      # KAFKA_HEAP_OPTS: "-Xmx256m -Xms256m -XX:+UseG1GC"  # Set JVM heap size to 256MB
      KAFKA_NUM_PARTITIONS: 3
    # deploy:
    #   resources:
    #     limits:
    #       memory: 5G
    # networks:
    #   - kafka_network
    depends_on:
      - zookeeper

  kafka3:
    image: wurstmeister/kafka
    tty: true
    restart: always
    container_name: kafka3
    ports:
      - "9094:9094"
    environment:
      # broker id
      KAFKA_BROKER_ID: 3
      KAFKA_ADVERTISED_HOST_NAME: kafka3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
      KAFKA_LOG_RETENTION_MS: 600000  # 10 menit
      # KAFKA_LOG_SEGMENT_BYTES: 1048576  # 1 MB
      # KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1 GB
      # KAFKA_HEAP_OPTS: "-Xmx256m -Xms256m -XX:+UseG1GC"  # Set JVM heap size to 256MB
      KAFKA_NUM_PARTITIONS: 5
    # deploy:
    #   resources:
    #     limits:
    #       memory: 5G
    # networks:
    #   - kafka_network
    depends_on:
      - zookeeper

  mongo:
    image: mongo
    restart: always
    ports:
      - 27017:27017
    # environment:
      # MONGO_INITDB_ROOT_USERNAME: root
      # MONGO_INITDB_ROOT_PASSWORD: example
    volumes:
        - ./mongo:/data/db
    # networks:
    #   - mongo_network

  mongo-express:
    image: mongo-express
    restart: always
    ports:
      - 8081:8081
    environment:
      # ME_CONFIG_MONGODB_ADMINUSERNAME: root
      # ME_CONFIG_MONGODB_ADMINPASSWORD: example
      # ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/
      ME_CONFIG_MONGODB_URL: mongodb://mongo:27017/
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: password
    # networks:
    #   - mongo_network
    depends_on:
      - mongo

  influxdb:
    image: influxdb:latest
    container_name: influxdb
    ports:
      - "8086:8086"
    volumes:
      - ./influxDB:/var/lib/influxdb
    # networks:
    #   - influxdb_network
    env_file:
      - ./influxDB/.env
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "4000:3000"  # Menggunakan port 4000 untuk Grafana
    # networks:
    #   - influxdb_network
    environment:
      GF_SERVER_ROOT_URL: http://localhost:4000  # Memastikan URL root sesuai
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: 12345678
    volumes:
      - ./grafana:/var/lib/grafana
    restart: always
    depends_on:
      - influxdb

  # nginx:
  #   image: nginx:latest
  #   container_name: nginx_load_balancer
  #   ports:
  #     - "8004:80"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #   depends_on:
  #     - p_wave_detector_load_balance
  #   # networks:
  #   #   - nginx_network
  #   restart: always

  data_provider:
    container_name: data_provider
    build:
      context: ./data_provider
    # networks:
    #   - kafka_network
    tty: true
    # deploy:
    #   resources:
    #     limits:
    #       memory: 1G
    depends_on:
      - kafka1
    restart: always

  p_wave_detector:
    build:
      context: ./p_wave_detector
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      replicas: 5
      # resources:
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       count: 1
        #       capabilities: [ gpu ]
        # limits:
        #   memory: 5G
    # networks:
    #   - kafka_network
    #   - influxdb_network
    tty: true
    depends_on:
      - kafka1
    restart: always

  # load_balancer:
  #   build:
  #     context: ./load_balancer
  #   deploy:
  #     replicas: 1
  #   # networks:
  #   #   - kafka_network
  #   #   - nginx_network
  #   tty: true
  #   depends_on:
  #     - kafka1
  #   restart: always

  # p_wave_detector_load_balance:
  #   build:
  #     context: ./p_wave_detector_load_balance
  #   ports:
  #     - "8004"
  #   # environment:
  #   #   - NVIDIA_VISIBLE_DEVICES=all
  #   deploy:
  #     replicas: 5
  #     # resources:
  #       # reservations:
  #       #   devices:
  #       #     - driver: nvidia
  #       #       count: 1
  #       #       capabilities: [ gpu ]
  #       # limits:
  #       #   memory: 5G
  #   # networks:
  #   #   - kafka_network
  #   #   - influxdb_network
  #   #   - nginx_network
  #   tty: true
  #   depends_on:
  #     - kafka1
  #   restart: always

  restarter:
    image: docker:cli
    restart: unless-stopped
    volumes: ["/var/run/docker.sock:/var/run/docker.sock"]
    entrypoint: ["/bin/sh","-c"]
    command:
      - |
        while true; do
          # docker ps

          sleep 600
          docker restart paper-eews-p_wave_detector_load_balance-1
          docker restart paper-eews-p_wave_detector-1
          docker restart paper-eews-data_saver-1
          
          # for topic in $(docker exec kafka1 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list); do
          #   for partition in $(docker exec kafka1 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --describe --topic $topic | grep 'Partition:' | awk '{print $2}'); do
          #     docker exec kafka1 /opt/kafka/bin/kafka-delete-records.sh --bootstrap-server kafka1:9092 --offset-json "{\"partitions\":[{\"topic\":\"$topic\",\"partition\":$partition,\"offset\":10}]}"
          #   done
          # done
          
          sleep 30
          docker restart paper-eews-p_wave_detector_load_balance-2
          docker restart paper-eews-p_wave_detector-2
          docker restart paper-eews-data_saver-2

          sleep 30
          docker restart paper-eews-p_wave_detector_load_balance-3
          docker restart paper-eews-p_wave_detector-3
          docker restart paper-eews-data_saver-3

          # for topic in $(docker exec kafka2 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka2:9093 --list); do
          #   for partition in $(docker exec kafka2 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka2:9093 --describe --topic $topic | grep 'Partition:' | awk '{print $2}'); do
          #     docker exec kafka2 /opt/kafka/bin/kafka-delete-records.sh --bootstrap-server kafka2:9093 --offset-json "{\"partitions\":[{\"topic\":\"$topic\",\"partition\":$partition,\"offset\":10}]}"
          #   done
          # done

          sleep 30
          docker restart paper-eews-p_wave_detector_load_balance-4
          docker restart paper-eews-p_wave_detector-4
          docker restart paper-eews-data_saver-4
          
          sleep 30
          docker restart paper-eews-p_wave_detector_load_balance-5
          docker restart paper-eews-p_wave_detector-5
          docker restart paper-eews-data_saver-5

          # for topic in $(docker exec kafka3 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka3:9094 --list); do
          #   for partition in $(docker exec kafka3 /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka3:9094 --describe --topic $topic | grep 'Partition:' | awk '{print $2}'); do
          #     docker exec kafka3 /opt/kafka/bin/kafka-delete-records.sh --bootstrap-server kafka3:9094 --offset-json "{\"partitions\":[{\"topic\":\"$topic\",\"partition\":$partition,\"offset\":10}]}"
          #   done
          # done
        done

  loc_mag_detector:
    build:
      context: ./loc_mag_detector
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      replicas: 1
      # resources:
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       count: 1
        #       capabilities: [ gpu ]
        # limits:
        #   memory: 4G
    # networks:
    #   - kafka_network
    #   - influxdb_network
    tty: true
    depends_on:
      - kafka1
    restart: always

  data_saver:
    build:
      context: ./data_saver
    deploy:
      replicas: 5
      # resources:
      #   limits:
      #     memory: 5G
    volumes:
      - ./data_saver/data_archive:/mnt/data
    # networks:
    #   - kafka_network
    #   - influxdb_network
    #   - mongo_network
    tty: true
    depends_on:
      - kafka1
      - influxdb
      - mongo
      - mongo-express
    restart: always

  api_server:
    container_name: api_server
    build:
      context: ./api_server
    ports:
      - "3333:3333"
    # networks:
    #   - kafka_network
    tty: true
    deploy:
      resources:
        limits:
          memory: 1G
    depends_on:
      - kafka1
    restart: always

  # fast_api:
  #   container_name: fast_api
  #   build:
  #     context: ./fast_api
  #   ports:
  #     - "3333:3333"
  #   networks:
  #     - kafka_network
  #   tty: true
  #   depends_on:
  #     - kafka
  #   restart: always

# networks:
#   nginx_network:
#     driver: bridge
#   kafka_network:
#     driver: bridge
#   influxdb_network:
#     driver: bridge
#   mongo_network:
#     driver: bridge